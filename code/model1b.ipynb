{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Model 3** - Embeddings + GMM\n",
    "\n",
    "- Following through from experience of Model-1 where TF-IDF KNN failed to determine user sentiment effectively, now I will explore more advanced model aimed at dealing with unsupervised clustering with much tighter accuracy.\n"
   ],
   "id": "1bbea00ac8acf0d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import + Configuration setup",
   "id": "dc12e986ad98e559"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:12.988069500Z",
     "start_time": "2026-02-20T12:32:07.040564500Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "K = 5\n",
    "MIN_REVIEWS = 30     # cluster only products with >= this many usable reviews\n",
    "TEST_FRAC = 0.10     # 90/10 split within product\n",
    "TEXT_COL = \"text_model\"   # change if yours is different\n",
    "ID_COL = \"item_id\"\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LOAD DATA",
   "id": "1d3d276fc05dcaaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:18.991540400Z",
     "start_time": "2026-02-20T12:32:16.988859500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Search from the notebook folder downward + one level up\n",
    "roots = [Path.cwd(), Path.cwd().parent]\n",
    "\n",
    "candidates = []\n",
    "for root in roots:\n",
    "    candidates += list(root.rglob(\"reviews_stitched.csv\"))\n",
    "    candidates += list(root.rglob(\"reviews_stitched.csv.gz\"))\n",
    "    candidates += list(root.rglob(\"user_reviews.csv\"))\n",
    "    candidates += list(root.rglob(\"user_reviews.csv.gz\"))\n",
    "\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"Could not find reviews_stitched/user_reviews csv(.gz) under current project folders.\")\n",
    "\n",
    "# pick the biggest file (usually the real dataset)\n",
    "candidates = sorted(candidates, key=lambda p: p.stat().st_size, reverse=True)\n",
    "path = candidates[0]\n",
    "\n",
    "print(\"Found:\", path.resolve())\n",
    "df_raw = pd.read_csv(path, low_memory=False)\n",
    "print(\"df_raw shape:\", df_raw.shape)\n",
    "print(\"Columns:\", len(df_raw.columns))\n",
    "\n"
   ],
   "id": "28303f81158a9e46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: C:\\Users\\Ben_h\\Ironhack\\Ironhack-week6\\ai-user-reviews-agg-project\\data\\user_reviews.csv\n",
      "df_raw shape: (67992, 28)\n",
      "Columns: 28\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Cleaned Model Dataframe",
   "id": "83b31a9edb26ba65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:21.584389100Z",
     "start_time": "2026-02-20T12:32:21.123273700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# product id\n",
    "if \"id\" not in df_raw.columns:\n",
    "    raise KeyError(\"Expected product id column 'id' not found.\")\n",
    "df_raw[\"item_id\"] = df_raw[\"id\"].astype(str)\n",
    "\n",
    "# text_model = title + text\n",
    "title = df_raw[\"reviews.title\"].fillna(\"\").astype(str) if \"reviews.title\" in df_raw.columns else \"\"\n",
    "text  = df_raw[\"reviews.text\"].fillna(\"\").astype(str)  if \"reviews.text\" in df_raw.columns else \"\"\n",
    "\n",
    "df_raw[\"text_model\"] = (title.str.strip() + \". \" + text.str.strip()).str.strip()\n",
    "df_raw[\"text_model\"] = df_raw[\"text_model\"].str.replace(r\"^\\.\\s*\", \"\", regex=True)\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = (s or \"\").lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "df_raw[\"text_model\"] = df_raw[\"text_model\"].map(normalize_text)\n",
    "\n",
    "# keep only what we need in THIS notebook\n",
    "keep = [\"item_id\", \"text_model\"]\n",
    "\n",
    "# optional metadata for reporting\n",
    "for c in [\"name\", \"brand\", \"categories\"]:\n",
    "    if c in df_raw.columns:\n",
    "        keep.append(c)\n",
    "\n",
    "# evaluation-only rating (never used in embeddings)\n",
    "if \"reviews.rating\" in df_raw.columns:\n",
    "    keep.append(\"reviews.rating\")\n",
    "\n",
    "df_model = df_raw[keep].copy()\n",
    "\n",
    "print(\"df_model shape:\", df_model.shape)\n",
    "print(\"df_model columns:\", df_model.columns.tolist())\n",
    "display(df_model.head(5))\n",
    "\n"
   ],
   "id": "76df31eb61fd54a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model shape: (67992, 6)\n",
      "df_model columns: ['item_id', 'text_model', 'name', 'brand', 'categories', 'reviews.rating']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                item_id                                         text_model  \\\n",
       "0  AVqkIhwDv8e3D1O-lebb  kindle. this product so far has not disappoint...   \n",
       "1  AVqkIhwDv8e3D1O-lebb  very fast. great for beginner or experienced p...   \n",
       "2  AVqkIhwDv8e3D1O-lebb  beginner tablet for our 9 year old son.. inexp...   \n",
       "3  AVqkIhwDv8e3D1O-lebb  good!!!. i've had my fire hd 8 two weeks now a...   \n",
       "4  AVqkIhwDv8e3D1O-lebb  fantastic tablet for kids. i bought this for m...   \n",
       "\n",
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "2  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "4  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  Amazon   \n",
       "\n",
       "                                          categories  reviews.rating  \n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...             5.0  \n",
       "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...             5.0  \n",
       "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...             5.0  \n",
       "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...             4.0  \n",
       "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...             5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>text_model</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviews.rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>kindle. this product so far has not disappoint...</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>very fast. great for beginner or experienced p...</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>beginner tablet for our 9 year old son.. inexp...</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>good!!!. i've had my fire hd 8 two weeks now a...</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>fantastic tablet for kids. i bought this for m...</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Filter usable rows\n",
   "id": "2c8007e39809041b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:24.761820200Z",
     "start_time": "2026-02-20T12:32:24.710952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "K = 3\n",
    "MIN_REVIEWS = 30\n",
    "TEST_FRAC = 0.10\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "df_model[\"text_len\"] = df_model[\"text_model\"].fillna(\"\").astype(str).str.len()\n",
    "\n",
    "# basic usable text filter (tune if needed)\n",
    "df_cluster = df_model[df_model[\"text_len\"] >= 10].copy()\n",
    "\n",
    "counts = df_cluster[\"item_id\"].value_counts()\n",
    "eligible_items = counts[counts >= MIN_REVIEWS].index\n",
    "df_cluster = df_cluster[df_cluster[\"item_id\"].isin(eligible_items)].copy()\n",
    "\n",
    "print(\"Eligible items:\", len(eligible_items))\n",
    "print(\"Eligible rows:\", len(df_cluster))\n"
   ],
   "id": "1c992c568d7dbb53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible items: 42\n",
      "Eligible rows: 67618\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPLIT 90/10",
   "id": "d75084848d2d1720"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:27.958647200Z",
     "start_time": "2026-02-20T12:32:26.945794800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "assert \"df_cluster\" in globals(), \"df_cluster not defined. Run the filtering cell first.\"\n",
    "assert \"item_id\" in df_cluster.columns, df_cluster.columns.tolist()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def split_within_item(g, test_frac=0.10):\n",
    "    n = len(g)\n",
    "    test_n = max(1, int(round(n * test_frac)))\n",
    "    idx = g.index.to_numpy()\n",
    "    test_idx = rng.choice(idx, size=test_n, replace=False)\n",
    "    g = g.copy()\n",
    "    g[\"split\"] = \"train\"\n",
    "    g.loc[test_idx, \"split\"] = \"test\"\n",
    "    return g\n",
    "\n",
    "df_split = (\n",
    "    df_cluster\n",
    "    .groupby(\"item_id\", group_keys=False)\n",
    "    .apply(split_within_item, test_frac=0.10)\n",
    ")\n",
    "\n",
    "KEEP_COLS = [\"item_id\", \"text_model\", \"name\", \"brand\", \"categories\", \"reviews.rating\", \"text_len\", \"split\"]\n",
    "df_split = df_split[KEEP_COLS].copy()\n",
    "\n",
    "\n",
    "print(df_split[\"split\"].value_counts())\n",
    "print(\"df_split columns:\", df_split.columns.tolist())\n",
    "\n",
    "\n"
   ],
   "id": "de741287851402a8",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['item_id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     18\u001B[39m df_split = (\n\u001B[32m     19\u001B[39m     df_cluster\n\u001B[32m     20\u001B[39m     .groupby(\u001B[33m\"\u001B[39m\u001B[33mitem_id\u001B[39m\u001B[33m\"\u001B[39m, group_keys=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     21\u001B[39m     .apply(split_within_item, test_frac=\u001B[32m0.10\u001B[39m)\n\u001B[32m     22\u001B[39m )\n\u001B[32m     24\u001B[39m KEEP_COLS = [\u001B[33m\"\u001B[39m\u001B[33mitem_id\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtext_model\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mname\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mbrand\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcategories\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mreviews.rating\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtext_len\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m df_split = \u001B[43mdf_split\u001B[49m\u001B[43m[\u001B[49m\u001B[43mKEEP_COLS\u001B[49m\u001B[43m]\u001B[49m.copy()\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(df_split[\u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m].value_counts())\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mdf_split columns:\u001B[39m\u001B[33m\"\u001B[39m, df_split.columns.tolist())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\frame.py:4384\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4382\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[32m   4383\u001B[39m         key = \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[32m-> \u001B[39m\u001B[32m4384\u001B[39m     indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcolumns\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[32m1\u001B[39m]\n\u001B[32m   4386\u001B[39m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[32m   4387\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) == \u001B[38;5;28mbool\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6302\u001B[39m, in \u001B[36mIndex._get_indexer_strict\u001B[39m\u001B[34m(self, key, axis_name)\u001B[39m\n\u001B[32m   6299\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   6300\u001B[39m     keyarr, indexer, new_indexer = \u001B[38;5;28mself\u001B[39m._reindex_non_unique(keyarr)\n\u001B[32m-> \u001B[39m\u001B[32m6302\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6304\u001B[39m keyarr = \u001B[38;5;28mself\u001B[39m.take(indexer)\n\u001B[32m   6305\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[32m   6306\u001B[39m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6355\u001B[39m, in \u001B[36mIndex._raise_if_missing\u001B[39m\u001B[34m(self, key, indexer, axis_name)\u001B[39m\n\u001B[32m   6352\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   6354\u001B[39m not_found = \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask.nonzero()[\u001B[32m0\u001B[39m]].unique())\n\u001B[32m-> \u001B[39m\u001B[32m6355\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m not in index\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyError\u001B[39m: \"['item_id'] not in index\""
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:32:37.634777500Z",
     "start_time": "2026-02-20T12:32:37.601774800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"df_split columns:\", df_split.columns.tolist())\n",
    "print(\"index names:\", df_split.index.names)\n"
   ],
   "id": "255f89c752392a39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_split columns: ['text_model', 'name', 'brand', 'categories', 'reviews.rating', 'text_len', 'split']\n",
      "index names: [None]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Embeddings",
   "id": "1bf4909d8deef930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T12:39:35.762580300Z",
     "start_time": "2026-02-20T12:32:40.630370400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = df_split[\"text_model\"].tolist()\n",
    "\n",
    "E = embedder.encode(df_split[\"text_model\"].tolist(), batch_size=128, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "E = embedder.encode(texts, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "E = normalize(E)\n",
    "\n",
    "print(\"Embeddings:\", E.shape)\n",
    "\n"
   ],
   "id": "b49baf8d89dfd66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben_h\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 529/529 [03:24<00:00,  2.59it/s]\n",
      "Batches: 100%|██████████| 1057/1057 [03:12<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (67618, 384)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:25:52.057816Z",
     "start_time": "2026-02-18T15:25:52.033056300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"df_split rows:\", len(df_split), \"E rows:\", E.shape[0])\n",
    "print(\"df_split columns:\", df_split.columns.tolist())\n"
   ],
   "id": "2b0fc5e65601f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_split rows: 67618 E rows: 67618\n",
      "df_split columns: ['text_model', 'name', 'brand', 'categories', 'reviews.rating', 'text_len', 'split', 'cluster']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:27:54.658997800Z",
     "start_time": "2026-02-18T15:27:54.627597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"has item_id?\", \"item_id\" in df_split.columns)\n",
    "print(df_split.columns.tolist())\n"
   ],
   "id": "42b27c5062c9dd97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has item_id? False\n",
      "['text_model', 'name', 'brand', 'categories', 'reviews.rating', 'text_len', 'split', 'cluster']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:28:21.299384700Z",
     "start_time": "2026-02-18T15:28:21.265390600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pick the right source df that definitely has item_id:\n",
    "SOURCE = df_cluster  # or df_raw, whichever has item_id aligned to df_split.index\n",
    "\n",
    "df_split[\"item_id\"] = SOURCE.loc[df_split.index, \"item_id\"].values\n",
    "assert \"item_id\" in df_split.columns\n"
   ],
   "id": "2fc1332ee9a8dfff",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fit GMM - per product",
   "id": "ab9d34b3a0fcae19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:28:26.325268700Z",
     "start_time": "2026-02-18T15:28:23.276160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "\n",
    "df_split[\"cluster\"] = -1\n",
    "\n",
    "# align df rows to embedding rows\n",
    "row_pos = pd.Series(range(len(df_split)), index=df_split.index)\n",
    "\n",
    "for item_id, g in df_split.groupby(\"item_id\"):\n",
    "    g_train = g[g[\"split\"] == \"train\"]\n",
    "    g_test  = g[g[\"split\"] == \"test\"]\n",
    "\n",
    "    if len(g_train) < K:\n",
    "        continue\n",
    "\n",
    "    X_train_item = E[row_pos.loc[g_train.index].values]\n",
    "\n",
    "    gmm = GaussianMixture(\n",
    "        n_components=K,\n",
    "        covariance_type=\"diag\",\n",
    "        reg_covar=1e-5,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    gmm.fit(X_train_item)\n",
    "\n",
    "    df_split.loc[g_train.index, \"cluster\"] = gmm.predict(X_train_item)\n",
    "\n",
    "    if len(g_test) > 0:\n",
    "        X_test_item = E[row_pos.loc[g_test.index].values]\n",
    "        df_split.loc[g_test.index, \"cluster\"] = gmm.predict(X_test_item)\n",
    "\n",
    "print(\"Assigned:\", int((df_split[\"cluster\"] >= 0).sum()))\n",
    "print(\"Unassigned:\", int((df_split[\"cluster\"] < 0).sum()))\n",
    "print(df_split[\"cluster\"].value_counts(dropna=False))\n",
    "\n",
    "\n"
   ],
   "id": "92d98e8991e240f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned: 67618\n",
      "Unassigned: 0\n",
      "cluster\n",
      "1    25630\n",
      "0    21342\n",
      "2    20646\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "21c763c46ca75965"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:28:30.498036600Z",
     "start_time": "2026-02-18T15:28:30.029338500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if \"reviews.rating\" not in df_split.columns:\n",
    "    raise KeyError(\"No 'reviews.rating' found. df_eval cannot be created for scoring.\")\n",
    "\n",
    "def rating_to_sentiment(r):\n",
    "    if pd.isna(r):\n",
    "        return np.nan\n",
    "    r = float(r)\n",
    "    if r <= 2:\n",
    "        return \"negative\"\n",
    "    if r == 3:\n",
    "        return \"neutral\"\n",
    "    return \"positive\"\n",
    "\n",
    "# df_eval = only rows we can evaluate\n",
    "df_eval = df_split[\n",
    "    (df_split[\"cluster\"] >= 0) &\n",
    "    (df_split[\"reviews.rating\"].notna())\n",
    "].copy()\n",
    "\n",
    "df_eval[\"true_sentiment\"] = df_eval[\"reviews.rating\"].map(rating_to_sentiment)\n",
    "\n",
    "# per-item mapping: clusters sorted by mean rating within that item\n",
    "maps = []\n",
    "for item_id, g in df_eval.groupby(\"item_id\"):\n",
    "    means = g.groupby(\"cluster\")[\"reviews.rating\"].mean().sort_values()\n",
    "    if len(means) < 3:\n",
    "        continue\n",
    "    order = means.index.tolist()\n",
    "    maps.append([item_id, order[0], order[1], order[2]])\n",
    "\n",
    "item_map = pd.DataFrame(maps, columns=[\"item_id\", \"neg_c\", \"neu_c\", \"pos_c\"])\n",
    "\n",
    "df_eval = df_eval.merge(item_map, on=\"item_id\", how=\"inner\")\n",
    "\n",
    "def cluster_to_sentiment_row(row):\n",
    "    if row[\"cluster\"] == row[\"neg_c\"]:\n",
    "        return \"negative\"\n",
    "    if row[\"cluster\"] == row[\"neu_c\"]:\n",
    "        return \"neutral\"\n",
    "    if row[\"cluster\"] == row[\"pos_c\"]:\n",
    "        return \"positive\"\n",
    "    return np.nan\n",
    "\n",
    "df_eval[\"pred_sentiment\"] = df_eval.apply(cluster_to_sentiment_row, axis=1)\n",
    "\n",
    "print(\"df_eval shape:\", df_eval.shape)\n",
    "print(df_eval[[\"true_sentiment\",\"pred_sentiment\"]].head(5))\n",
    "\n"
   ],
   "id": "c9e0a57894b59f51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_eval shape: (67618, 14)\n",
      "  true_sentiment pred_sentiment\n",
      "0       positive       positive\n",
      "1       positive       negative\n",
      "2       positive        neutral\n",
      "3       positive       positive\n",
      "4       positive        neutral\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plot Results",
   "id": "1cd88d82f82b38e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:28:37.299336100Z",
     "start_time": "2026-02-18T15:28:36.608291200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_true = df_eval[\"true_sentiment\"]\n",
    "y_pred = df_eval[\"pred_sentiment\"]\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 4))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "labels = [\"negative\",\"neutral\",\"positive\"]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"true_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
    "display(cm_df)\n"
   ],
   "id": "f36a503672fc294d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3465\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.0547    0.5308    0.0991      2466\n",
      "     neutral     0.0419    0.3104    0.0738      2880\n",
      "    positive     0.9503    0.3409    0.5018     62272\n",
      "\n",
      "    accuracy                         0.3465     67618\n",
      "   macro avg     0.3489    0.3940    0.2249     67618\n",
      "weighted avg     0.8789    0.3465    0.4689     67618\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               pred_negative  pred_neutral  pred_positive\n",
       "true_negative           1309           742            415\n",
       "true_neutral            1290           894            696\n",
       "true_positive          21341         19702          21229"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_negative</th>\n",
       "      <th>pred_neutral</th>\n",
       "      <th>pred_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_negative</th>\n",
       "      <td>1309</td>\n",
       "      <td>742</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neutral</th>\n",
       "      <td>1290</td>\n",
       "      <td>894</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_positive</th>\n",
       "      <td>21341</td>\n",
       "      <td>19702</td>\n",
       "      <td>21229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Final evaluation of Un-Supervised learning\n",
    "\n",
    "Unsupervised result: Clusters capture structure (topic/style/length) but don’t consistently align with sentiment labels. Performance vs rating-derived sentiment is low on macro F1, especially for negative/neutral due to class imbalance and label noise.\n",
    "\n",
    "Lasting comment: Because unsupervised clusters did not align reliably with sentiment (low macro-F1, minority classes poorly separated), we switched to a supervised text-classification approach to achieve robust negative/neutral/positive sentiment accuracy\n",
    "\n",
    "Decision: Switch to supervised learning."
   ],
   "id": "df5633a82798273a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
